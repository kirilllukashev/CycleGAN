{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aJozvWfnnoT"
   },
   "source": [
    "# CYCLE GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fb8JQDvpPcf"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HkPGqC2UIylN",
    "outputId": "12962377-e9f0-445e-f3c7-8443b9cf734c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/gbarto/.local/lib/python3.8/site-packages (1.20.2)\n",
      "Requirement already satisfied: torch in /home/gbarto/.local/lib/python3.8/site-packages (1.8.1)\n",
      "Requirement already satisfied: wandb in /home/gbarto/.local/lib/python3.8/site-packages (0.10.30)\n",
      "Requirement already satisfied: torchvision in /home/gbarto/.local/lib/python3.8/site-packages (0.9.1)\n",
      "Requirement already satisfied: sklearn in /home/gbarto/.local/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: tqdm in /home/gbarto/.local/lib/python3.8/site-packages (4.60.0)\n",
      "Requirement already satisfied: matplotlib in /home/gbarto/.local/lib/python3.8/site-packages (3.4.2)\n",
      "Requirement already satisfied: typing-extensions in /home/gbarto/.local/lib/python3.8/site-packages (from torch) (3.10.0.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/lib/python3/dist-packages (from wandb) (1.14.0)\n",
      "Requirement already satisfied: Click>=7.0 in /home/gbarto/.local/lib/python3.8/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in /home/gbarto/.local/lib/python3.8/site-packages (from wandb) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /home/gbarto/.local/lib/python3.8/site-packages (from wandb) (3.16.0)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from wandb) (5.3.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /home/gbarto/.local/lib/python3.8/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/gbarto/.local/lib/python3.8/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/gbarto/.local/lib/python3.8/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/gbarto/.local/lib/python3.8/site-packages (from wandb) (3.1.14)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/gbarto/.local/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /home/gbarto/.local/lib/python3.8/site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: pathtools in /home/gbarto/.local/lib/python3.8/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/lib/python3/dist-packages (from wandb) (2.22.0)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /home/gbarto/.local/lib/python3.8/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/gbarto/.local/lib/python3.8/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/gbarto/.local/lib/python3.8/site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: scikit-learn in /home/gbarto/.local/lib/python3.8/site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/gbarto/.local/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/gbarto/.local/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/gbarto/.local/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: urllib3>=1.10.0 in /usr/lib/python3/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.25.8)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from sentry-sdk>=0.4.0->wandb) (2019.11.28)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/gbarto/.local/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/gbarto/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/gbarto/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/gbarto/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.6.3)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /home/gbarto/.local/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install numpy torch wandb torchvision sklearn tqdm matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3hia8WKIylQ"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gqaxKhPrpODm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "\n",
    "from torchvision import transforms,datasets\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm.auto import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivFk2ni4IylT"
   },
   "source": [
    "### Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d33pS9fKpgcm",
    "outputId": "f5295718-4bd5-478c-dc40-c6e6970c4625"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQxQghw1GUuA",
    "outputId": "111cf7f3-d7cb-495d-ee1a-2d031d4d506d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlalunedeidees\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWy_jrEcn6ly"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "maDivVjq5Xq_"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "class ImageLoader():\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "    def load(self, path):\n",
    "        out = Image.open(path).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            out = self.transform(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Tzdwvo5D5pwN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.transform = transform\n",
    "        self.loader = ImageLoader(transform)\n",
    "        \n",
    "        self.paths = self.get_paths(root)\n",
    "        \n",
    "    def get_paths(self, root):\n",
    "        path = os.path.join(root, '*')\n",
    "        paths = glob.glob(path)\n",
    "        \n",
    "        exts = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')\n",
    "        paths = filter(lambda p: p.endswith(exts), paths)\n",
    "        paths = list(paths)\n",
    "        \n",
    "        return paths\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.paths[index]\n",
    "        img = self.loader.load(path)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7Vmee1om5q_x"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def get_transform(image_size, aug=False):\n",
    "    if aug:\n",
    "        bigger_image_size = (image_size // 8 + 1) * 8\n",
    "        ts = [\n",
    "            transforms.Resize((bigger_image_size, bigger_image_size)),\n",
    "            transforms.RandomResizedCrop((image_size, image_size)),\n",
    "            transforms.RandomHorizontalFlip()\n",
    "        ]\n",
    "    else:\n",
    "        ts = [transforms.Resize((image_size, image_size))]\n",
    "        \n",
    "    ts += [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ]\n",
    "    \n",
    "    return transforms.Compose(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5q8tQv3vMLZm",
    "outputId": "258471be-920f-4294-9f18-7026ebaee18e"
   },
   "outputs": [],
   "source": [
    "# !wget https://people.eecs.berkeley.edu/%7Etaesung_park/CycleGAN/datasets/horse2zebra.zip\n",
    "# !unzip horse2zebra.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "e9xgWVg65wrG"
   },
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "\n",
    "train_transforms = get_transform(image_size, aug=True)\n",
    "train_dataset_a = ImageDataset(root='horse2zebra/trainA', transform=train_transforms)\n",
    "train_dataset_b = ImageDataset(root='horse2zebra/trainB', transform=train_transforms)\n",
    "\n",
    "val_transforms = get_transform(image_size, aug=False)\n",
    "val_dataset_a = ImageDataset(root='horse2zebra/testA', transform=val_transforms)\n",
    "val_dataset_b = ImageDataset(root='horse2zebra/testB', transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "n_Q-lqCO55FJ"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class JointDataLoader():\n",
    "    def __init__(self, dataset_a, dataset_b, batch_size, shuffle=False, num_workers=1):\n",
    "        self.dataset_a = dataset_a\n",
    "        self.dataset_b = dataset_b\n",
    "        \n",
    "        self.dataloader_a = DataLoader(\n",
    "            dataset=dataset_a,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=True\n",
    "        )\n",
    "        self.dataloader_b = DataLoader(\n",
    "            dataset=dataset_b,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=True\n",
    "        )\n",
    "        \n",
    "        self.n = min(len(self.dataloader_a), len(self.dataloader_b))\n",
    "        \n",
    "        if shuffle:\n",
    "            self.dataloader_a = self.infinit_dataloader(self.dataloader_a)\n",
    "            self.dataloader_b = self.infinit_dataloader(self.dataloader_b)\n",
    "        \n",
    "    def infinit_dataloader(self, dataloader):\n",
    "        while True:\n",
    "            for x in dataloader:\n",
    "                yield x\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for _, a, b in zip(range(self.n), self.dataloader_a, self.dataloader_b):\n",
    "            yield a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YOlIFlgobyZ"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lxuTefKTIylb"
   },
   "outputs": [],
   "source": [
    "class DownSampleBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=4,\n",
    "                 stride=2, padding=1,activation='ReLU'):\n",
    "        super(DownSampleBlock, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding)\n",
    "        self.ins = nn.InstanceNorm2d(out_planes)\n",
    "        self.relu = nn.ReLU() if activation == 'ReLU' else nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.ins(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "# DownSampleBlock(64 * k_ch, 128 * k_ch)\n",
    "# заменит\n",
    "# nn.Conv2d(64*k_ch,128*k_ch,4,2,1,bias=False),\n",
    "# nn.InstanceNorm2d(128*k_ch),\n",
    "# nn.LeakyReLU(0.2)\n",
    "\n",
    "class CenterDownSampleBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=2,\n",
    "                 stride=1, padding=0):\n",
    "        super(CenterDownSampleBlock, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding)\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# CenterDownSampleBlock(128 * k_ch, 256 * k_ch)\n",
    "# заменит\n",
    "# nn.Conv2d(128*k_ch,256*k_ch,2,bias=False),\n",
    "# nn.LeakyReLU(0.2),\n",
    "\n",
    "class CenterUpSampleBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=2,\n",
    "                 stride=1, padding=0):\n",
    "        super(CenterUpSampleBlock, self).__init__()\n",
    "\n",
    "        self.trans_conv = nn.ConvTranspose2d(\n",
    "            in_planes, out_planes, kernel_size=kernel_size, \n",
    "            stride=stride, padding=padding,\n",
    "        )\n",
    "        self.ins = nn.InstanceNorm2d(out_planes)\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.trans_conv(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# CenterUpSampleBlock(64 * k_ch, 128 * k_ch)\n",
    "# заменит\n",
    "# nn.ConvTranspose2d(256*k_ch,128*k_ch,2,bias=False),\n",
    "# nn.InstanceNorm2d(128*k_ch),\n",
    "# nn.LeakyReLU(0.2),\n",
    "\n",
    "class UpSampleBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=4,\n",
    "                 stride=2, padding=1, activation='ReLU',output_padding=0):\n",
    "        super(UpSampleBlock, self).__init__()\n",
    "\n",
    "        self.trans_conv = nn.ConvTranspose2d(\n",
    "            in_planes, out_planes, kernel_size=kernel_size,\n",
    "            stride=stride, padding=padding,output_padding=output_padding\n",
    "        )\n",
    "        self.ins = nn.InstanceNorm2d(out_planes)\n",
    "        self.relu = nn.ReLU() if activation == 'ReLU' else nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.trans_conv(x)\n",
    "        x = self.ins(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=4,\n",
    "                 stride=2, padding=1):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "\n",
    "        self.down_sample = DownSampleBlock(in_planes,out_planes,3,1,1,activation='ReLU')\n",
    "        self.conv2d = nn.Conv2d(out_planes,out_planes,3,1,1)\n",
    "        self.ins = nn.InstanceNorm2d(out_planes)\n",
    "#         self.relu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.down_sample(x)\n",
    "        x = self.conv2d(x)\n",
    "        x = self.ins(x)\n",
    "        x = x + identity\n",
    "        return x\n",
    "# UpSampleBlock(4 * k_ch, 2 * k_ch)\n",
    "# заменит\n",
    "# nn.ConvTranspose2d(4*k_ch,2*k_ch,4,2,1,bias=False),\n",
    "# nn.InstanceNorm2d(2*k_ch),\n",
    "# nn.LeakyReLU(0.2),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RPuVpt2vooAk"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super(Generator, self).__init__()\n",
    "        k_ch = 3 # number of color chanels\n",
    "        layers = [\n",
    "            DownSampleBlock(1*k_ch,64,7,1,3,activation='ReLU'),\n",
    "            DownSampleBlock(64,128,3,1,1,activation='ReLU'),\n",
    "            DownSampleBlock(128,256,3,1,1,activation='ReLU'),\n",
    "            \n",
    "            ResnetBlock(256,256),\n",
    "            ResnetBlock(256,256),\n",
    "            ResnetBlock(256,256),\n",
    "            ResnetBlock(256,256),\n",
    "            ResnetBlock(256,256),\n",
    "            ResnetBlock(256,256),\n",
    "#             ResnetBlock(256,256),\n",
    "#             ResnetBlock(256,256),\n",
    "#             ResnetBlock(256,256),\n",
    "            \n",
    "            \n",
    "            UpSampleBlock(256,128,3,1,1,activation='ReLU'),\n",
    "            UpSampleBlock(128,64,3,1,1,activation='ReLU'),\n",
    "#             UpSampleBlock(128,64,3,2,1),\n",
    "            nn.ConvTranspose2d(64,3,7,1,3),\n",
    "#             nn.InstanceNorm2d(3),\n",
    "            nn.Tanh()\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GtsI6NnH-Dis",
    "outputId": "2a6c9bb4-2d05-4c60-ce1c-339b263978fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128, 128])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = Generator(1)(train_dataset_a[0].reshape((1,3,128,128)))\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ADqHZxYznkso"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        k_ch = 3 # number of color chanels\n",
    "        layers = [\n",
    "            DownSampleBlock(1*k_ch,64,4,2,2,activation='LeakyReLU'),\n",
    "            DownSampleBlock(64,128,4,2,2,activation='LeakyReLU'),\n",
    "            DownSampleBlock(128,256,4,2,2,activation='LeakyReLU'),\n",
    "            DownSampleBlock(256,512,4,2,2,activation='LeakyReLU'),\n",
    "            DownSampleBlock(512,512,4,1,2,activation='LeakyReLU'),\n",
    "\n",
    "#             DownSampleBlock(512,512),\n",
    "#             DownSampleBlock(512,512),\n",
    "\n",
    "            # nn.Conv2d(512,1,4,1,2),\n",
    "\n",
    "#             CenterDownSampleBlock(512,1),\n",
    "\n",
    "#             DownSampleBlock(256,512,4,1,1),\n",
    "            nn.Conv2d(512,1,4,1,1),\n",
    "            \n",
    "#             nn.Flatten(),\n",
    "            # nn.Linear(k_ch,1),\n",
    "#             nn.Sigmoid()\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMeMCtHu0NBs",
    "outputId": "a113c9e2-3a9c-4da0-d4cb-ceedc2759915"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 9, 9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Discriminator()(res).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hraYgsz_qIGh"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "amsOllJlD-kY"
   },
   "outputs": [],
   "source": [
    "def log_losses(title, losses, step):\n",
    "    title = f'{title}_losses'\n",
    "\n",
    "    loss_names = [\n",
    "        'gen_ab_loss',\n",
    "        'gen_ba_loss',\n",
    "        'cycle_aba_loss',\n",
    "        'cycle_bab_loss',\n",
    "        'indentity_a_loss',\n",
    "        'indentity_b_loss',\n",
    "        'disc_a_loss',\n",
    "        'disc_b_loss'\n",
    "    ]\n",
    "    \n",
    "    for loss, loss_name in zip(losses, loss_names):\n",
    "        wandb.log({f'{title}/{loss_name}': loss}, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "E5a_ZdkBHRmp"
   },
   "outputs": [],
   "source": [
    "\n",
    "def log_images(title, x, step,grid_size=(5,5)):\n",
    "    title = f'{title}'\n",
    "\n",
    "    x = x[:grid_size[0]*grid_size[1]].cpu()\n",
    "\n",
    "    imgs = make_grid(x, nrow=grid_size[0])\n",
    "    \n",
    "    wandb.log({f'{title}': [wandb.Image(imgs)]}, step=step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "1tp8zOIjCsxa"
   },
   "outputs": [],
   "source": [
    "def calc_disc_loss(a, b, gen_ab, disc_b, criterion):\n",
    "    z = a\n",
    "\n",
    "    b_fake = gen_ab(z)\n",
    "\n",
    "    out_real = disc_b(b)\n",
    "    out_fake = disc_b(b_fake)\n",
    "\n",
    "    target_real = torch.ones_like(out_real).to(device)\n",
    "    target_fake = torch.zeros_like(out_fake).to(device)\n",
    "\n",
    "    loss_real = criterion(out_real, target_real)\n",
    "    loss_fake = criterion(out_fake, target_fake)\n",
    "\n",
    "    disc_b_loss = loss_real + loss_fake\n",
    "    \n",
    "    return disc_b_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_losses_discs(gen_ab, gen_ba, disc_a, disc_b, a, b, criterion):\n",
    "    disc_b_loss = calc_disc_loss(a, b, gen_ab, disc_b, criterion)\n",
    "    disc_a_loss = calc_disc_loss(b, a, gen_ba, disc_a, criterion)\n",
    "\n",
    "    loss = disc_a_loss + disc_b_loss\n",
    "\n",
    "    losses = np.array([disc_a_loss.item(), disc_b_loss.item()])\n",
    "\n",
    "    return loss, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gen_loss(a, gen_ab, gen_ba, disc_b, criterion_bce, criterion_l2):\n",
    "    fake_b = gen_ab(a)\n",
    "    out_fake_b = disc_b(fake_b)\n",
    "    \n",
    "    target_fake = torch.ones_like(out_fake_b).to(device)\n",
    "    gen_ab_loss = criterion_bce(out_fake_b, target_fake)\n",
    "    \n",
    "    fake_ba = gen_ba(fake_b)\n",
    "    aba_loss = criterion_l2(fake_ba, a)\n",
    "    \n",
    "    return gen_ab_loss, aba_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_losses_gens(gen_ab, gen_ba, disc_a, disc_b, a, b, criterion_bce, criterion_l2):\n",
    "    gen_ab_loss, aba_loss = calc_gen_loss(a, gen_ab, gen_ba, disc_b, criterion_bce, criterion_l2)\n",
    "    gen_ba_loss, bab_loss = calc_gen_loss(b, gen_ba, gen_ab, disc_a, criterion_bce, criterion_l2)\n",
    "    \n",
    "    indentity_a_loss = criterion_l2(gen_ba(a), a)\n",
    "    indentity_b_loss = criterion_l2(gen_ab(b), b)\n",
    "\n",
    "    loss = gen_ab_loss + gen_ba_loss\n",
    "    loss = loss + aba_loss + bab_loss\n",
    "    loss = loss + indentity_a_loss + indentity_b_loss\n",
    "\n",
    "    losses = np.array([\n",
    "        gen_ab_loss.item(),\n",
    "        gen_ba_loss.item(),\n",
    "        aba_loss.item(),\n",
    "        bab_loss.item(),\n",
    "        indentity_a_loss.item(),\n",
    "        indentity_b_loss.item()\n",
    "    ])\n",
    "\n",
    "    return loss, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "BvewOystB5zX"
   },
   "outputs": [],
   "source": [
    "def train_step(gen_ab,gen_ba,disc_a,disc_b, a, b, criterion_bce,criterion_l2,optim_gens, optim_discs, step):\n",
    "    # calc losses gens\n",
    "    loss_gens, losses_gens  = calc_losses_gens(gen_ab, gen_ba, disc_a, disc_b, a, b, criterion_bce, criterion_l2)\n",
    "    # take steps\n",
    "    optim_gens.zero_grad()\n",
    "    loss_gens.backward()\n",
    "    optim_gens.step()\n",
    "\n",
    "    # calc losses for discs\n",
    "    loss_discs, losses_discs  = calc_losses_discs(gen_ab, gen_ba, disc_a, disc_b, a, b, criterion_bce)\n",
    "    # take steps\n",
    "    optim_discs.zero_grad()\n",
    "    loss_discs.backward()\n",
    "    optim_discs.step()\n",
    "    \n",
    "    # log lossses\n",
    "    losses = np.concatenate([\n",
    "      losses_gens,\n",
    "      losses_discs,\n",
    "    ])\n",
    "    \n",
    "    log_losses('Train', losses, step)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "wLwGzPD-8nrm"
   },
   "outputs": [],
   "source": [
    "def train_epoch(gen_ab,gen_ba,disc_a,disc_b, criterion_bce,criterion_l2,optim_gens, optim_discs, dataloader, step):\n",
    "    gen_ab.train()\n",
    "    gen_ba.train()\n",
    "    disc_a.train()\n",
    "    disc_b.train()\n",
    "    \n",
    "    for a, b in dataloader:\n",
    "        a = a.to(device)\n",
    "        b = b.to(device)\n",
    "        \n",
    "        train_step(gen_ab,gen_ba,disc_a,disc_b, a, b, criterion_bce,criterion_l2,optim_gens, optim_discs, step)\n",
    "        if step % 100 == 0:\n",
    "            a, b = next(iter(valloader))\n",
    "            a.to(device)\n",
    "            b.to(device)\n",
    "\n",
    "            log_generate_cycles(a, b, gen_ab, gen_ba, step)\n",
    "    \n",
    "        step += 1\n",
    "    return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "pSS8f22iIylh"
   },
   "outputs": [],
   "source": [
    "\n",
    "def log_cycle(a, gen_ab, gen_ba, step, title='forward cycle'):\n",
    "    # to middle\n",
    "    a1 = a[:1].to(device)\n",
    "    a_b = gen_ab(a1)\n",
    "    # to tail\n",
    "    a_b_a = gen_ba(a_b)\n",
    "    imgs= torch.cat((a1,a_b,a_b_a),0)\n",
    "\n",
    "    log_images(title, imgs, step, grid_size=(3, 1))\n",
    "\n",
    "\n",
    "def log_generate_cycles(a, b, gen_ab, gen_ba, step):\n",
    "    log_cycle(a, gen_ab, gen_ba, step, title='Images/forward cycle')\n",
    "    log_cycle(b, gen_ba, gen_ab, step, title='Images/reverse cycle')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "pDuY0Wsx9HoZ"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_epoch(gen_ab,gen_ba,disc_a,disc_b, criterion_bce, valloader, step):\n",
    "    gen_ab.eval()\n",
    "    gen_ba.eval()\n",
    "    disc_a.eval()\n",
    "    disc_b.eval()\n",
    "    \n",
    "    (a,b),*_ = valloader\n",
    "    # b = a\n",
    "    a.to(device)\n",
    "    b.to(device)\n",
    "    \n",
    "    log_generate_cycles(a,b,gen_ab,gen_ba,step)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "5QMcIgW2qkIp"
   },
   "outputs": [],
   "source": [
    "def train(gen_ab,gen_ba,disc_a,disc_b, criterion_bce,criterion_l2,optim_gens, optim_discs, trainloader,valloader, epochs,step=0):\n",
    "#     step = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        step = train_epoch(gen_ab,gen_ba,disc_a,disc_b, criterion_bce,criterion_l2,optim_gens, optim_discs, trainloader, step)\n",
    "        val_epoch(gen_ab,gen_ba,disc_a,disc_b, criterion_bce,valloader, step)\n",
    "        wandb.log({'epoch': epoch}, step=step)\n",
    "#         step+=1\n",
    "    return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXjJ2FoRIyli"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "eWFWwyhwTK4Q"
   },
   "outputs": [],
   "source": [
    "concatenate = lambda a,b:list(a) + list(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "gltQF9bY61iV"
   },
   "outputs": [],
   "source": [
    "gen_ab = Generator(0).to(device) # FIXME: del 0\n",
    "gen_ba = Generator(0).to(device)\n",
    "disc_a = Discriminator().to(device)\n",
    "disc_b = Discriminator().to(device)\n",
    "\n",
    "criterion_bce = nn.MSELoss()\n",
    "criterion_l2  = nn.L1Loss()\n",
    "\n",
    "params_gens  = concatenate(gen_ab.parameters(),gen_ba.parameters())\n",
    "params_discs = concatenate(disc_a.parameters(),disc_b.parameters())\n",
    "\n",
    "optim_gens  = torch.optim.Adam(params_gens, lr=0.0002, betas=(0.3, 0.999))\n",
    "optim_discs = torch.optim.Adam(params_discs, lr=0.0002, betas=(0.3, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLc_rRo5Iylj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "NZ0apQtu8aJf"
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "\n",
    "trainloader = JointDataLoader(\n",
    "    dataset_a=train_dataset_a,\n",
    "    dataset_b=train_dataset_b,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8\n",
    ")\n",
    "valloader = JointDataLoader(\n",
    "    dataset_a=val_dataset_a,\n",
    "    dataset_b=val_dataset_b,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  9 16:43:56 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:8B:00.0 Off |                    0 |\n",
      "| N/A   53C    P0    44W / 250W |  23159MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       764      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A    173960      C   /usr/bin/python3                23151MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6d918ee8b2f941809c193e17fdbad13e",
      "320c4716e0944df5a86323fb9b2288d8",
      "d7feccd63bd94868bbd365a0e0836a23",
      "f0825fcac64a434f977f782542275ed6",
      "7df606edb20849f5b0de106c71afa2af",
      "4e622edc7798414e9e418612ea48856d",
      "3cc59825827246caa8410632ef42be6f",
      "7220e7088f6642c681685cad59ce4448"
     ]
    },
    "id": "wi8y2htD2kUC",
    "outputId": "b3fea569-2830-4fe6-e0de-1ad0032018c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">youthful-smoke-92</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/lalunedeidees/GAN\" target=\"_blank\">https://wandb.ai/lalunedeidees/GAN</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/lalunedeidees/GAN/runs/3jmuuajc\" target=\"_blank\">https://wandb.ai/lalunedeidees/GAN/runs/3jmuuajc</a><br/>\n",
       "                Run data is saved locally in <code>/home/gbarto/project/wandb/run-20210509_164356-3jmuuajc</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "wandb.init(\n",
    "    project='GAN',\n",
    "#     config={'n_res': 2}\n",
    ")\n",
    "step = train(gen_ab,gen_ba,disc_a,disc_b, criterion_bce,criterion_l2,optim_gens, optim_discs, trainloader,valloader, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qE28W4fWIylk"
   },
   "outputs": [],
   "source": [
    " # if you want to continue train:\n",
    "# step = train(gen_ab,gen_ba,disc_a,disc_b, criterion_bce,criterion_l2,optim_gens, optim_discs, trainloader, epochs=100,step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ejH2uZsIIylm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  9 17:01:26 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:8B:00.0 Off |                    0 |\n",
      "| N/A   59C    P0   215W / 250W |  23159MiB / 32510MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       764      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A    173960      C   /usr/bin/python3                23151MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UTv_WstWIylm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vss7-L90Iylm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4GHYzpwmIyln"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4r5_SvfgIylo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-Im2RyNIylo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BkOBy8ZBIylz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_tQ-0AbDoQI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CYCLE_GAN_MAIN(2).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "320c4716e0944df5a86323fb9b2288d8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cc59825827246caa8410632ef42be6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4e622edc7798414e9e418612ea48856d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d918ee8b2f941809c193e17fdbad13e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d7feccd63bd94868bbd365a0e0836a23",
       "IPY_MODEL_f0825fcac64a434f977f782542275ed6"
      ],
      "layout": "IPY_MODEL_320c4716e0944df5a86323fb9b2288d8"
     }
    },
    "7220e7088f6642c681685cad59ce4448": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7df606edb20849f5b0de106c71afa2af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7feccd63bd94868bbd365a0e0836a23": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e622edc7798414e9e418612ea48856d",
      "placeholder": "​",
      "style": "IPY_MODEL_7df606edb20849f5b0de106c71afa2af",
      "value": " 0.72MB of 0.72MB uploaded (0.00MB deduped)\r"
     }
    },
    "f0825fcac64a434f977f782542275ed6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7220e7088f6642c681685cad59ce4448",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3cc59825827246caa8410632ef42be6f",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
